\chapter{Conclusions}\label{conclusion}
This chapter discusses the general conclusions, contributions, and the future work.

\section{General Conclusions}
We conclude that the operating system library version updates are affecting 
the output images from HCP preprocessing pipelines. The analysis of results obtained by processing subjects in 
different CentOS versions shows that inter-OS differences in these 
images are visually substantial.

For finding the inter-run differences, we analysed results 
obtained from processing subjects twice in the same condition. No 
inter-run differences were identified from these results. We 
conclude that pseudo-random processes in the HCP preprocessing pipelines are not causing any differences.
%\todo{What if the same slient crashes occur in every run?}

The likely causes, of the inter-OS differences are, (i) the evolution 
of math libraries over the time and, (ii) the instability of the pipelines, i.e, 
these pipelines amplify the small numerical differences that are 
created by the differences in the underlying operating system 
libraries.

There are two ways to tackle this problem. The easy but less preferred 
solution to this problem would be masking the instabilities. The 
preferred solution is to fix the instabilities in the pipeline.

The masking of instabilities can be done by using, (i) single operating 
system for the processing of subjects, (ii) containerizing the 
pipelines so that the processing is done on a more controlled 
environment (researchers can control the updates to libraries and 
operating system), (iii) increasing the numerical precision of the 
pipelines, (iv) following stricter truncation and rounding standard 
(IEEE 754), (v) building static executable by removing the host 
operating system library dependency.

The masking of instabilities is said to be less preferred because it just 
makes the problem invisible but the instability still remains. If we 
conduct the study with a change of condition like a newer version of 
operating system or on an entirely different operating system, the 
results we obtain would be different.

The preferred solution is to fix the particular functions/scripts in 
the preprocessing pipelines that are unstable. To reduce the 
variance in results considerably and thus, to the output 
more stable and reliable.

\section{Contributions}
All the software tools developed for this study are open-source.
%\todo{Be careful here: you used a lot of stuff which is not yours. You should say "All the software tools developed for this project are open-source."}
 Docker images created for this study are hosted on 
 Dockerhub\footnote{\url{https://hub.docker.com/r/bigdatalabteam/hcp-prefreesurfer/}}. 
 Dockerhub status shows that these images has been pulled from the 
 repository more than, 8000 times. Repro-tools can be used to analyze 
 the datasets to find out the differences in checksum or size 
 of files. It can also quantify the differences with the use of 
 metrics. Different metrics can be configured in Repro-tools 
 (verifyFiles script) to quantify the differences with respect to the 
 file formats. The differences in the files from PreFreeSurfer pipeline was presented at Neuroinformatics (INCF-2017) conference held at Kuala Lumpur, Malaysia\footnote{\url{https://abstracts.g-node.org/abstracts/1d0afd7e-0542-4b79-99df-e15c5e0e4487}}. The visualizations that we have added to the results section 
 portrays the effect of changing the operating system when
 conducting experiments. These images convey the message 
 that operating systems on which the preprocessing takes place have a 
 strong effect on the output image.

\section{Future work}
Though we could identify the differences in these files and quantify these differences using the metrics, the functions in the pipeline that causes these differences should be identified.
Pipelines should be studied in detail to identify the first instance of difference that gets created and how this difference is propagated through the pipeline.
Because the pipelines are linked to each other (previous pipeline's output becomes next pipeline's input), each pipeline must be examined in detail to find out if the pipeline just propagates the error, whether it amplifies them, or it creates new files with differences as well. 
Study can be extended to other pipelines in the HCP pipelines (e.g., fMRISurface and Diffusion Preprocessing pipeline).
