\chapter{Conclusion}\label{conclusion}
From the results we obtained from the preprocessing pipelines, PreFreeSurfer, FreeSurfer, PostFreeSurfer and fMRIVolume, we identified and quantified the differences. This chapter discusses the general findings from our study.

\section{General inferences}
From this study, we can conclude that the operating system library version updates are affecting the output images from HCP Preprocessing pipelines. The analysis of results we obtained by processing subjects in different CentOS versions, shows that inter-OS differences in these images are visually substantial. These variations in the output images due to the operating system library updates are causing reproducibility issues in HCP pipelines.

We had also analyzed the inter-run results where we ran PreFreeSurfer, FreeSurfer, PostFreeSurfer and fMRIVolume pipeline twice for each subject in the same condition. No inter-run differences were identified.

The likely causes, of these differences are, (i) the evolution of math libraries over the time (ii) the pipelines are unstable, i.e, these pipelines amplify the small numerical differences that are created by the differences in the underlying operating system libraries.

There are two ways to tackle this problem. The easy but less preferred solution to this problem would be masking the instabilities. But, the preferred solution is to fix the instabilities in the pipeline, that is, to make the pipelines more stable.

The masking of instabilities can be done by using, (i) single operating system for the processing of subjects, (ii) containerizing the pipelines so that the processing is done on a more controlled environment (researchers can control the updates to libraries and operating system), (iii) Increasing the numerical precision of the pipelines, (iv) Following stricter truncation and rounding standard (IEEE 754), (v) Building static executable by removing the host operating system library dependency.

The above mentioned way is said to be less preferred because it just makes the problem invisible but the instability still remains. If we conduct the study with a change of condition like a newer version of operating system or on an entirely different operating system, the results we obtain would be different.

The preferred solution is to fix the particular functions/scripts in the preprocessing pipelines that are unstable. This would reduce the variance in results considerably and thus, it could make the output more stable and reliable.

\section{Future work}
Though we could identify the files that are having differences and quantify these differences using the metrics, the functions in the pipeline that causes these differences should be identified.
Pipelines should be studied in detail to identify the first instance of difference that gets created and how this difference is propagated through the pipeline.
Since the pipelines are linked to each other (previous pipeline's output becomes next pipeline's input), each pipeline needs to be examined in detail to find out if the pipeline just propagates the error, whether it amplifies them and also if it creates new files with differences as well. 
Study can be extended to other pipelines in the HCP pipelines (e.g., fMRISurface and Diffusion Preprocessing pipeline).
