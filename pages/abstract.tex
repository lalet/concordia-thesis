\begin{abstract}
The lack of computational reproducibility threatens data science in 
several 
domains\footnote{\url{www.nature.com/news/1-500-scientists-lift-the-lid-on-reproducibility-1.19970}}. 
This study focus on neuroimaging pipelines and aims to (i) identify the 
effect of operating system on neuroimaging pipelines (ii) quantify the 
effect with the use of standard metrics. %(iii) verification of these 
differences to find out if they are visually substantial.


To conduct this study, a framework for evaluating the reproducibility 
of these neuroimaging pipelines was developed. The two major 
functionalities of this framework being, processing of the subjects and 
the analysis of the processed data. The framework consists of Docker 
containers, 
CBRAIN\footnote{\url{https://mcin-cnim.ca/technology/cbrain/}}, 
Boutiques\footnote{\url{http://boutiques.github.io/}} descriptors, 
Reprozip\footnote{\url{https://www.reprozip.org/}} and 
Repro-tools\footnote{\url{https://github.com/big-data-lab-team/repro-tools}}.



Docker images were created from CentOS versions which contained the HCP 
preprocessing pipelines. Boutiques descriptors were used for deploying 
these Docker containers to CBRAIN (a web-platform to manage computing 
resources and data). Provenance information of these pipelines were 
recorded using Reprozip. The identification and quantification of the 
differences were done using the Reprotools. Normalized root mean square 
error and dice coefficient of similarity were the metrics used for 
quantifying the differences. 


Two kinds of differences can occur in the output images, which are, 
inter-OS and inter-run differences. Inter-OS differences are 
differences that are created due to the changes in the operating system 
version. Inter-run differences are differences that occur with in the 
same condition due to reasons like pseudo-random process, silent 
crashes etc.

% Experiment description
We applied our reproducibility framework to the evaluation of the effect of the 
operating system on results produced by pipelines from the Human 
Connectome Project (HCP), a large open-data initiative to study the 
human brain. In particular, we focused on pre-processing pipelines for 
anatomical and functional data, namely PrefFreeSurfer, FreeSurfer, 
PostFreeSurfer and fMRIVolume. We used data from 5 subjects released by 
the HCP.

% Results
Results highlight substantial differences in the output of the HCP 
pipelines obtained in two versions of Linux (CentOS6 and CentOS7): 
inter-OS differences corresponding to normalized root mean square 
errors of up to 0.27 were observed, which corresponds to visually 
important differences. We provide visualizations of the most important 
differences for various pipeline steps. No meaningful inter-run 
differences were observed, which shows that the inter-OS differences do 
not originate from the use of pseudo-random numbers or silent crashes 
of the pipelines.

% Discussion
We hypothesize that the observed inter-OS differences come from 
numerical instabilities in the pipelines, triggered by rounding and 
truncation differences that originate in the update of mathematical 
libraries in different systems. An apparent solution to this issue 
is to freeze the execution environment using, for instance, software containers.
However, this would only mask instabilities while they should ultimately be
corrected in the pipelines.
\end{abstract}
